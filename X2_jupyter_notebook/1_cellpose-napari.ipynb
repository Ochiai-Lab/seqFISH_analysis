{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellposeを利用したsegmentation\n",
    "ここでは、細胞核の画像をもとに、ざっくりとcellposeを利用して自動的にsegmentationさせる。\n",
    "後で、人の目で補正していく。\n",
    "\n",
    "最初に、以下の\" \"の間に、githubからダウンロードしたフォルダのパスを指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 現在のディレクトリのパスを取得\n",
    "current_directory = os.getcwd()\n",
    "# 現在のディレクトリの2つ上の階層のパスを取得\n",
    "dir = os.path.dirname(current_directory)\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下では必要なモジュールをインポートする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-26 11:40:47,552 [INFO] WRITING LOG OUTPUT TO /Users/HiroshiOchiai/.cellpose/run.log\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, os, sys\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300 #要変更？ https://analytics-note.xyz/programming/matplotlib-figsize-dpi/\n",
    "from cellpose import utils, io\n",
    "import napari\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import closing, square, remove_small_objects\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from cellpose import models, io\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import plot\n",
    "import pyclesperanto_prototype as cle\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from tifffile import imwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# hard-code the paths of our input and output directories\n",
    "path_input = os.path.join(dir, \"1_processed_images\", \"3_diveded_files\")\n",
    "\n",
    "# 解析対象のpositionを選ぶ。ここは要変更\n",
    "pos_num =(\"Pos01\", \"Pos02\", \"Pos03\")\n",
    "\n",
    "\n",
    "for i in range(len(pos_num)) :\n",
    "    # ここは変更不要。RNA-seqFISHの最後の、poleA染色時の細胞核の画像。\n",
    "    nuc_path = os.path.join(path_input, pos_num[i], \"ND31_C4_TyR.tif\")\n",
    "    img_nuc = io.imread(nuc_path)\n",
    "    img_nuc_dim = img_nuc.shape # z, y, xの情報を入れる。\n",
    "    # 画像によってzの枚数が異なるため、Zの中央に相当する番号をmed_zとして決めておく。\n",
    "    med_z = round(img_nuc_dim[0]/2)\n",
    "    \n",
    "    \n",
    "    # サイズを1/5に圧縮。Cellposeでうまくsegmentationするために必要。1/5以外だとうまくいかない\n",
    "    resized_y = round(img_nuc_dim[1]/5)\n",
    "    resized_x = round(img_nuc_dim[2]/5)\n",
    "\n",
    "    \n",
    "    resized_img = resize(img_nuc,\n",
    "                               output_shape = (img_nuc_dim[0], resized_y, resized_x), # タプルである必要がある。\n",
    "                               order=1,\n",
    "                               mode=\"reflect\",\n",
    "                               preserve_range=True,\n",
    "                               anti_aliasing=False)\n",
    "\n",
    "    # 画像をさらに1.5 pixelのgauss blueでぼかす。これもcellposeでのsegmentationをうまく行かせるための操作\n",
    "    \n",
    "    blurred = cle.gaussian_blur(resized_img, sigma_x=1.5, sigma_y=1.5, sigma_z=0)\n",
    "    blurred_round = np.round(blurred)\n",
    "    \n",
    "\n",
    "    # RUN CELLPOSE\n",
    "\n",
    "    # DEFINE CELLPOSE MODEL\n",
    "    # model_type='cyto' or model_type='nuclei'\n",
    "    model = models.Cellpose(gpu=False, model_type='nuclei')\n",
    "\n",
    "    # define CHANNELS to run segementation on\n",
    "    # grayscale=0, R=1, G=2, B=3\n",
    "    # channels = [cytoplasm, nucleus]\n",
    "    # if NUCLEUS channel does not exist, set the second channel to 0\n",
    "    # channels = [0,0]\n",
    "    # IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
    "    # channels = [0,0] # IF YOU HAVE GRAYSCALE\n",
    "    # channels = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus\n",
    "    # channels = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
    "\n",
    "    # or if you have different types of channels in each image\n",
    "    channels = [1,0] # 細胞質が赤、核が青\n",
    "\n",
    "    # if diameter is set to None, the size of the cells is estimated on a per image basis\n",
    "    # you can set the average cell `diameter` in pixels yourself (recommended) \n",
    "    # diameter can be a list or a single number for all images\n",
    "\n",
    "    # you can run all in a list e.g.\n",
    "    # imgs = [io.imread(filename) in for filename in files]\n",
    "    masks, flows, styles, diams = model.eval(blurred_round, diameter= 25, channels=channels, do_3D=True, \n",
    "                                             cellprob_threshold=0.0, flow_threshold=0.4,\n",
    "                                            resample = False, net_avg=False) # diameterを設定しないとうまくいかなかった。\n",
    "    # io.masks_flows_to_seg(img, masks, flows, diams, files, channels)\n",
    "\n",
    "\n",
    "    # DISPLAY RESULTS\n",
    "    # from cellpose import plot\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    plot.show_segmentation(fig, blurred_round[med_z,:,:], masks[med_z,:,:], flows[0][med_z,:,:,:], channels=[0,0])\n",
    "    plt.tight_layout()\n",
    "    path_output = os.path.join(dir, \"1_processed_images\", \"4_segmentation\")\n",
    "    path = os.path.join(path_output, pos_num[i], \"01_nuc_seg_first_round_for_check.png\")\n",
    "    plt.savefig(path)\n",
    "    \n",
    "    image_to_process = resize(masks,\n",
    "                           output_shape = (img_nuc_dim[0], img_nuc_dim[1], img_nuc_dim[2]), # タプルである必要がある。\n",
    "                           order=None,\n",
    "                           mode=\"constant\",\n",
    "                           preserve_range=True,\n",
    "                           anti_aliasing=False)\n",
    "    \n",
    "    \n",
    "\n",
    "    # https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/basics/select_GPU.py\n",
    "\n",
    "    import pyclesperanto_prototype as cle\n",
    "\n",
    "    # list names of all available OpenCL-devices\n",
    "    print(\"Available OpenCL devices:\" + str(cle.available_device_names()))\n",
    "\n",
    "    # list CPUs and GPUs separately\n",
    "\n",
    "    gpu_devices = cle.available_device_names(dev_type=\"gpu\")\n",
    "    print(\"Available GPU OpenCL devices:\" + str(gpu_devices))\n",
    "\n",
    "    cpu_devices = cle.available_device_names(dev_type=\"cpu\")\n",
    "    print(\"Available CPU OpenCL devices:\" + str(cpu_devices))\n",
    "    \n",
    "    # https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/basics/count_blobs.ipynb\n",
    "    import pyclesperanto_prototype as cle\n",
    "\n",
    "    from skimage.io import imread, imsave, imshow\n",
    "    import matplotlib\n",
    "    import numpy as np\n",
    "\n",
    "    # initialize GPU\n",
    "    cle.select_device(gpu_devices[0])\n",
    "        \n",
    "    \n",
    "    # load data\n",
    "    image = image_to_process.astype(np.uint32)\n",
    "    print(\"Loaded image size: \" + str(image.shape))\n",
    "\n",
    "    # push image to GPU memory\n",
    "    input = cle.push(image)\n",
    "    print(\"Image size in GPU: \" + str(input.shape))\n",
    "    \n",
    "    \n",
    "    input.dtype\n",
    "\n",
    "    # show result\n",
    "#     cle.imshow(input[30,:,:], labels=True)\n",
    "    erode = input\n",
    "    cle.erode_labels(labels_input = input,\n",
    "                    labels_destination = erode,\n",
    "                    radius = 1,\n",
    "                    relabel_islands = False)\n",
    "    dilate = input\n",
    "    cle.dilate_labels(erode,dilate,2)\n",
    "    open_1 = input\n",
    "    cle.opening_labels(dilate,open_1,8)\n",
    "    dilate_2 = input\n",
    "    cle.dilate_labels(open_1,dilate_2,4)\n",
    "\n",
    "    # show result\n",
    "#     cle.imshow(dilate_2[30,:,:], labels=True)\n",
    "\n",
    "\n",
    "    # データをtiffとして吐き出す。これをimportすれば、segmentationに利用できる。\n",
    "    path_output = os.path.join(dir, \"1_processed_images\", \"4_segmentation\")\n",
    "    path = os.path.join(path_output, pos_num[i], \"01_nuc_seg_first_round.tif\")\n",
    "    imwrite(path, dilate_2.astype(np.uint16))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行前に以下を修正する必要がある。\n",
    "pos_numは\"Pos01\"などと、撮影視野番号を入れる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の設定が終われば、以下を実行する。\n",
    "Napariが開くため、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HiroshiOchiai/opt/anaconda3/envs/cellpose_napari/lib/python3.8/site-packages/napari_tools_menu/__init__.py:165: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    }
   ],
   "source": [
    "# 解析対象のpositionを選ぶ。ここは要変更\n",
    "pos_N = 1\n",
    "target_nuc = \"ND31_C4_TyR.tif\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time, os, sys\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300 #要変更？ https://analytics-note.xyz/programming/matplotlib-figsize-dpi/\n",
    "from cellpose import utils, io\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "import napari\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "import tifffile\n",
    "\n",
    "pos_num = f\"Pos{pos_N:02d}\"\n",
    "path_input = os.path.join(dir, \"1_processed_images\", \"3_diveded_files\")\n",
    "path_output = os.path.join(dir, \"1_processed_images\", \"4_segmentation\")\n",
    "\n",
    "\n",
    "# ここは変更不要。RNA-seqFISHの最後の、poleA染色時の細胞核の画像。\n",
    "nuc_path = os.path.join(path_input, pos_num, target_nuc)\n",
    "nuclei = io.imread(nuc_path)\n",
    "\n",
    "path = os.path.join(path_output, pos_num, \"01_nuc_seg_first_round.tif\")\n",
    "nuc_seg = tifffile.imread(path)\n",
    "# membranes = tifffile.imread('../images/cells_membrane.tif')\n",
    "\n",
    "\n",
    "viewer = napari.view_image(\n",
    "    nuclei,\n",
    "#     contrast_limits=[0, 1],\n",
    "    ndisplay=2,\n",
    ")\n",
    "\n",
    "\n",
    "from skimage import filters\n",
    "\n",
    "\n",
    "edges = filters.scharr(nuclei)\n",
    "\n",
    "nuclei_layer = viewer.layers['nuclei']\n",
    "nuclei_layer.blending = 'additive'\n",
    "nuclei_layer.colormap = 'green'\n",
    "\n",
    "viewer.add_image(\n",
    "    edges,\n",
    "    blending='additive',\n",
    "    colormap='magenta',\n",
    "    opacity=0.5,\n",
    "    contrast_limits=(0.0,0.04)\n",
    ")\n",
    "\n",
    "\n",
    "path = os.path.join(path_output, pos_num, \"DNAseqFIS_foci_enhance_stack.tif\")\n",
    "\n",
    "seqFISH = tifffile.imread(path)\n",
    "# membranes = tifffile.imread('../images/cells_membrane.tif')\n",
    "\n",
    "viewer.add_image(\n",
    "    seqFISH,\n",
    "    blending='additive',\n",
    "    colormap='blue',\n",
    "    gamma=2.0,\n",
    "    contrast_limits=(0.0,1594.0)\n",
    ")\n",
    "\n",
    "labels_layer = viewer.add_labels(nuc_seg.astype(int), \n",
    "                                 name='nuc_seg',\n",
    "                                opacity=0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napariでの修正が終わったら以下を実行する。\n",
    "修正したデータが取り込まれ、データが保存される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# napariの中で、細胞核に相当するlabelのデータを取得する。pythonでは数値が0から始まるため、\n",
    "# 細胞核が4番目に来ているはず。\n",
    "nuc_seg2 = viewer.layers[3].data\n",
    "\n",
    "# データをtiffとして吐き出す。これをimportすれば、segmentationに利用できる。\n",
    "from tifffile import imwrite\n",
    "\n",
    "path = os.path.join(path_output, pos_num, \"02_nuc_seg_human_corrected.tif\")\n",
    "imwrite(path, nuc_seg2.astype(np.uint16))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b677cdb9023b207d35ce23a8ed7417dbe21dab4481e6f79ba3afb231afc71037"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
